from datetime import datetime

import numpy as np
import pytz
from matplotlib import rcParams
from nilmtk import DataSet
from sklearn import preprocessing
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import cross_val_score
import matplotlib.pyplot as plt

from datareader import Datareader as dr
from dataprepairer import Dataprepairer as dp
import pandas as pd
from joblib import dump, load

from imblearn.over_sampling import RandomOverSampler
from signals import Signals

"""
labels:
0: fridge
1: dish washer
2: light0
3: microwave
4: electric space heater
5: electric stove
6: light 1
7: light 2
8: electric oven
9: washer dryer
"""

SAMPLE_PERIOD = 60
rcParams['figure.figsize'] = (13, 6)
PRINT_STATS = True


def parse_input_mutli_appliances(x, y, number_of_appliances):
    multi_label = number_of_appliances + 1
    result = []
    other_states = []

    for _i in range(1, len(y) - 1):
        if y[_i] == multi_label:
            X = x[_i].copy()
            Z = []
            left = _i - 1
            right = _i + 1
            while y[left] == multi_label and left > 0:
                left -= 1
            while y[right] == multi_label and right < len(y):
                right += 1

            assert (not y[left] == multi_label) and (not y[right] == multi_label)

            # we subtract the average power of the base signal from the multiple appliance segment
            average_avg = 0
            average_min = 0
            if x[_i][0] > x[left][0]:
                average_avg = x[left][0]
                average_min = x[left][1]
                Z.append(y[left])

            if x[_i][0] > x[right][0]:
                average_avg += x[right][0]
                average_min += x[right][1]
                Z.append(y[right])

            # we subtract both neighbors from the segment
            if average_avg == x[right][0] + x[left][0] and y[left] == y[right]:
                average_avg = average_avg / 2
                average_min = average_min / 2

            print("X before: " + str(X) + " average: " + str(average_avg))
            X[0] -= average_avg
            X[1] -= average_min if average_min < x[_i][1] else x[_i][1]
            print("X after: " + str(X))
            # print("average: " + str(average_avg) + " min: " + str(average_min))

            # TODO: change std as well

            result.append(X)
            other_states.append(np.unique(Z))

    return result, other_states


train = DataSet("../data/redd.5h")
test = DataSet("../data/redd.5h")
entire = DataSet("../data/redd.5h")
building = 1

train_start = datetime(2011, 4, 18, 10, tzinfo=pytz.UTC)
train_end = datetime(2011, 5, 1, tzinfo=pytz.UTC)

test_start = datetime(2011, 5, 12, tzinfo=pytz.UTC)
test_end = datetime(2011, 5, 20, tzinfo=pytz.UTC)

train.set_window(start=train_start.strftime("%Y-%m-%d %H:%M:%S"), end=train_end.strftime("%Y-%m-%d %H:%M:%S"))
test.set_window(start=test_start.strftime("%Y-%m-%d %H:%M:%S"), end=test_end.strftime("%Y-%m-%d %H:%M:%S"))
train_elec = train.buildings[1].elec
test_elec = test.buildings[1].elec

order_appliances = ['fridge', 'microwave', 'washer dryer',
                    'dish washer']  # , 'dish washer'  # 'electric oven', 'electric stove'
breakpoint_classification = [
    {"max_power": 300, "on_power_threshold": 100, "min_on": int(60 / SAMPLE_PERIOD),
     "min_off": int(12 / SAMPLE_PERIOD)},
    {"max_power": 3000, "on_power_threshold": 200, "min_on": int(12 / SAMPLE_PERIOD),
     "min_off": int(30 / SAMPLE_PERIOD)},
    {"max_power": 2500, "on_power_threshold": 100, "min_on": int(1800 / SAMPLE_PERIOD),
     "min_off": int(160 / SAMPLE_PERIOD)},
    {"max_power": 2500, "on_power_threshold": 100, "min_on": int(1800 / SAMPLE_PERIOD),
     "min_off": int(600 / SAMPLE_PERIOD)}
]

selection_of_houses = {1: ["fridge", "microwave", 'washer dryer', 'dish washer'],  #
                       2: ["fridge", "microwave"],
                       3: ["fridge", "microwave", 'washer dryer'],
                       4: ['washer dryer']}
datetime_format = "%Y-%m-%d %H:%M:%S"
window_selection_of_houses = {1: (datetime(2011, 4, 18, 10, tzinfo=pytz.UTC).strftime(datetime_format),
                                  datetime(2011, 5, 1, tzinfo=pytz.UTC).strftime(datetime_format)),
                              2: (None, datetime(2011, 5, 1, tzinfo=pytz.UTC).strftime(datetime_format)),
                              3: (None, datetime(2011, 4, 27, tzinfo=pytz.UTC).strftime(datetime_format)),
                              4: (None, datetime(2011, 5, 1, tzinfo=pytz.UTC).strftime(datetime_format))}
houses = [1, 2, 3, 4]

breakpoint_clf = MLPClassifier(alpha=1e-6, hidden_layer_sizes=16, activation="relu", learning_rate="adaptive",
                               max_iter=500)
label_clf = MLPClassifier(alpha=1e-6, hidden_layer_sizes=16, activation="relu", learning_rate="adaptive")

multi_appliance_clf = MLPClassifier(alpha=1e-6, hidden_layer_sizes=16, activation="relu", learning_rate="adaptive")

# training
x1, y1, x2, y2 = None, None, None, None

for i in range(0, len(houses)):
    house = houses[i]
    print("training house: " + str(house))
    selection = selection_of_houses[house]
    window_start, window_end = window_selection_of_houses[house]
    train.set_window(start=window_start, end=window_end)
    train_elec = train.buildings[house].elec

    train_appliances = dr.load_appliances_selection(train_elec, order_appliances, selection, SAMPLE_PERIOD)
    train_total = dr.load_total_power_consumption(train_elec, selection, SAMPLE_PERIOD)
    assert len(train_appliances[0]) == len(train_total)


    train_states = dp.get_states(train_appliances, breakpoint_classification)
    train_breakpoints, train_states_on_breakpoints = dp.states_to_breakpoints(train_states)
    train_input_br = dp.parse_input_breakpoint_identifier(train_total, train_breakpoints)

    train_labels = dp.parse_output_segment_labeling(train_states_on_breakpoints)
    train_segments = dp.get_segments(train_total, train_breakpoints)
    train_input_seg_label = dp.parse_input_segment_labeling(train_segments, train_labels)

    x1 = train_input_br if x1 is None else np.concatenate((x1, train_input_br))
    y1 = train_breakpoints if y1 is None else np.concatenate((y1, train_breakpoints))
    x2 = train_input_seg_label if x2 is None else np.concatenate((x2, train_input_seg_label))
    y2 = train_labels if y2 is None else np.concatenate((y2, train_labels))

ros = RandomOverSampler(random_state=0)
x1_resampled, y1_resampled = ros.fit_resample(x1, y1)
breakpoint_clf.fit(x1_resampled, y1_resampled)
x2_resampled, y2_resampled = ros.fit_resample(x2, y2)
label_clf.fit(x2_resampled, y2_resampled)

house = 1
selection = selection_of_houses[house]
test_elec = test.buildings[house].elec
test_appliances = dr.load_appliances_selection(test_elec, order_appliances, selection, SAMPLE_PERIOD)
test_total = dr.load_total_power_consumption(test_elec, selection, SAMPLE_PERIOD)

# test_appliance_breakpoints = dp.get_appliance_breakpoints(test_appliances, breakpoint_classification)
# test_breakpoints = dp.parse_output_breakpoint_identifier(test_appliance_breakpoints)
test_states = dp.get_states(test_appliances, breakpoint_classification)
test_breakpoints, test_states_on_breakpoints = dp.states_to_breakpoints(test_states)

test_input = dp.parse_input_breakpoint_identifier(test_total, test_breakpoints)

pred_clf_breakpoints = breakpoint_clf.predict(test_input)

print("breakpoint classifier")
print(classification_report(test_breakpoints, pred_clf_breakpoints))
print(confusion_matrix(test_breakpoints, pred_clf_breakpoints))

test_labels = dp.parse_output_segment_labeling(test_states_on_breakpoints)

test_segments = dp.get_segments(test_total, test_breakpoints)
test_segments_after_clf = dp.get_segments(test_total, pred_clf_breakpoints)
test_input2 = dp.parse_input_segment_labeling(test_segments, test_labels)

pred_label_clf = label_clf.predict(test_input2)

print("segment labeler")
print(classification_report(test_labels, pred_label_clf))
print(confusion_matrix(test_labels, pred_label_clf))

"""scores_breakpoints = cross_val_score(breakpoint_clf, test_input, test_breakpoints, cv=10)
print("Accuracy breakpoints: %0.2f (+/- %0.2f)" % (scores_breakpoints.mean(), scores_breakpoints.std() * 2))
scores_labeler = cross_val_score(label_clf, test_input2, test_labels, cv=10)
print("Accuracy labels: %0.2f (+/- %0.2f)" % (scores_labeler.mean(), scores_labeler.std() * 2))
scores_labeler = cross_val_score(label_clf, test_input2_after_clf, test_labels_after_clf, cv=10)
print("Accuracy combined: %0.2f (+/- %0.2f)" % (scores_labeler.mean(), scores_labeler.std() * 2))"""

test_input3, other_labels = parse_input_mutli_appliances(test_input2, test_labels, len(order_appliances))
new_labels = label_clf.predict(test_input3)

correct_labels = dp.breakpoint_states_to_labels(test_states_on_breakpoints)

actual_labels = 0
actual_labels_without_multi = 0
actual_labels_with_multi = 0
count_correct_labels_without_multi = 0
count_correct_labels_with_multi = 0
for t, c in zip(pred_label_clf, correct_labels):
    # print("got: "+ str(t)+ " wanted: "+str(c))
    actual_labels += len(c)
    if not (t == len(order_appliances) + 1):
        if len(c) == 0:
            actual_labels_without_multi += 1
            count_correct_labels_without_multi += 1 if t == 0 else 0
        else:
            actual_labels_without_multi += len(c)
            count_correct_labels_without_multi += 1 if t in c else 0

for i, n in enumerate(np.where(np.array(test_labels) == 4)[0]):
    t = np.unique(np.append(other_labels[i], new_labels[i]))
    c = correct_labels[n]
    actual_labels_with_multi += len(c)
    for _t in t:
        count_correct_labels_with_multi += 1 if _t in c else 0

print("actual labels = " + str(actual_labels))
print("total correct = " + str(actual_labels_without_multi) + " total predicted= " + str(
    count_correct_labels_without_multi))
print("total correct multi = " + str(actual_labels_with_multi) + " total predicted= " + str(
    count_correct_labels_with_multi))

# some statistics
if PRINT_STATS:
    test_appliance_breakpoints = test_states.T
    nr_appliance_breakpoints = np.count_nonzero(test_appliance_breakpoints, axis=1)
    nr_breakpoints = np.count_nonzero(test_breakpoints)
    for br, ap in zip(test_appliance_breakpoints, test_appliances):
        ap["breakpoints"] = br * 400
    print("House " + str(house))
    print("### breakpoints ###")
    print("Breakpoints per appliance:")
    print(nr_appliance_breakpoints)
    print("Total Breakpoints:")
    print(nr_breakpoints)
    print("Total occurences of multile breakpoints at once:")
    print(np.sum(nr_appliance_breakpoints) - nr_breakpoints)
    print("Plotting breakpoints per appliance")
    range_plot = [(0, int(25000 / SAMPLE_PERIOD)), (int(24000 / SAMPLE_PERIOD), int(30000 / SAMPLE_PERIOD)),
                  (int(165000 / SAMPLE_PERIOD), int(172500 / SAMPLE_PERIOD)),
                  (int(335000 / SAMPLE_PERIOD), int(350000 / SAMPLE_PERIOD))]
    for ap, (x, y) in zip(test_appliances, range_plot):
        plt.plot(ap[x:y])
        plt.show()

    print(" ")

    (unique, counts) = np.unique(test_labels, return_counts=True)
    frequencies = np.asarray((unique, counts)).T
    print("### labels ###")
    print("total occurences of labels")
    print(frequencies)
    print("total predicted occurences of labels")
    print(np.asarray(np.unique(pred_label_clf, return_counts=True)).T)
    print("distinct labels after multi appliance dissagregation:")
    # print(np.asarray(np.unique(addedLabels, return_counts=True)).T)

    print(" ")
    print("### segments ###")
    print("total segments")
    print(len(test_segments))
